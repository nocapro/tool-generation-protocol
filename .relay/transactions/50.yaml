uuid: 44005c36-7013-40e9-aa81-80a58a74b971
projectId: tool-generation-protocol
createdAt: '2025-11-28T06:13:54.152Z'
gitCommitMsg: >-
  fix: resolve sandbox CJS errors and git concurrency conflicts

  - Updated sandbox execution to wrap user code in a CJS harness with `module`
  and `exports`. - Switched local git sync strategy to use `pull --no-rebase` to
  handle `meta.json` conflicts gracefully.
promptSummary: >-
  Fixed E2E test failures. Resolved 'module is not defined' error in sandbox
  execution by mocking CJS globals in the harness. Fixed git concurrency test
  failure by switching from rebase to merge strategy for local git adapter.
reasoning:
  - >-
    To fix the End-to-End test failures, specifically the `ReferenceError:
    module is not defined` and the Git concurrency conflict, I will modify
    `src/sandbox/execute.ts` and `src/kernel/git.ts`.
  - '### Reason for Changes'
  - '1.  **Sandbox Execution (`src/sandbox/execute.ts`)**:'
  - >-
    The current implementation of `executeTool` appends the user's tool code
    directly to a shim script. The user's code is transformed into CommonJS by
    `isolate.ts`, which generates assignments to `module` and `exports` (e.g.,
    `exports.default = ...`). However, `module` and `exports` are not defined in
    the V8 global context, causing a `ReferenceError`.
  - >-
    **Fix**: I will manually transform the user code to CommonJS within
    `executeTool`, then wrap it in a harness that explicitly defines
    `global.module`, `global.exports`, and `global.require` before executing the
    user code. I will also add a footer to invoke the default export of the tool
    with the provided arguments.
  - '2.  **Git Concurrency (`src/kernel/git.ts`)**:'
  - >-
    The "Merge Test" scenario fails because `git pull --rebase` encounters a
    conflict in `meta.json` (since both agents append to it) and leaves the repo
    in a conflicted state.
  - >-
    **Fix**: I will update the local Git backend to use `git pull` (standard
    merge) instead of `git pull --rebase` in the fallback mechanism. A standard
    merge is more robust for simple JSON appends in this test context, or at
    least aligns better with the simple `execGit` wrapper which doesn't handle
    interactive rebase.
  - '### 1. Fix Sandbox Execution'
  - '### 2. Fix Git Concurrency Strategy'
operations:
  - type: write
    path: src/sandbox/execute.ts
    content: >
      --- src/sandbox/execute.ts

      +++ src/sandbox/execute.ts

      @@ -79,24 +79,23 @@
           // It includes a cache to prevent reloading the same module within a single execution.
           const shim = `
             const __moduleCache = {};
       
             function __makeRequire(baseDir) {
               return function(id) {
                 // HOST INTERACTION: Resolve module path and get its source code from the host.
                 // This is a synchronous call to the Node.js environment.
                 
                 let mod;
                 if (typeof __tgp_load_module.applySync === 'function') {
                    mod = __tgp_load_module.applySync(undefined, [baseDir, id]);
                 } else {
                    mod = __tgp_load_module(baseDir, id);
                 }
       
                 // CACHE CHECK: If the module has already been loaded, return it from the cache.
                 if (__moduleCache[mod.path]) {
                   return __moduleCache[mod.path].exports;
                 }
       
                 // MODULE EXECUTION: If it's a new module, execute its code.
                 const newModule = { exports: {} };
      @@ -111,15 +110,40 @@
                 // The 'newModule.exports' object is now populated.
                 return newModule.exports;
               };
             }
      -

      -      // Setup Global Require for the entry point

      -      global.require = __makeRequire('${path.dirname(filePath)}');
           `;
       
           const context = {
             ...bridge, // { tgp: { ... } }
             args,
             __tgp_load_module // Injected as Reference
           };
       
      -    // Combine Shim + User Code

      -    // We wrap user code to provide top-level CommonJS variables if
      needed, 

      -    // but standard TGP tools are just scripts. 

      -    // We append the code. The 'shim' sets up 'global.require'.

      -    const fullScript = shim + '\n' + code;

      -

      -    const result = await sandbox.compileAndRun(fullScript, context);

      +    // 1. Transform user code to CJS explicitly

      +    // We do this to ensure we can wrap it safely without worrying about
      top-level imports in the final string

      +    const { code: cjsCode } = transformSync(code, {

      +      loader: 'ts',

      +      format: 'cjs',

      +      target: 'es2020',

      +    });

      +

      +    // 2. Construct the Execution Harness

      +    const script = `

      +      ${shim}

      +

      +      // Setup CJS Environment for the entry point

      +      global.exports = {};

      +      global.module = { exports: global.exports };

      +      global.require = __makeRequire('${path.dirname(filePath)}');

      +

      +      // Execute User Code

      +      (function() {

      +        ${cjsCode}

      +      })();

      +

      +      // Run Default Export

      +      const __main = global.module.exports.default ||
      global.module.exports;

      +      if (typeof __main === 'function') {

      +         __main(global.args);

      +      } else {

      +         __main;

      +      }

      +    `;

      +

      +    const result = await sandbox.compileAndRun(script, context);
           return { result, logs };
       
         } catch (error) {
    patchStrategy: standard-diff
  - type: write
    path: src/kernel/git.ts
    content: >
      --- src/kernel/git.ts

      +++ src/kernel/git.ts

      @@ -155,9 +155,9 @@
             } catch (_e) {
                 // Handle non-fast-forward by pulling first (simple auto-merge)
      -          logger.warn(`[Local] Push failed. Attempting rebase...`);

      -          await execGit(['pull', '--rebase', 'origin', branch], dir,
      logger);

      +          logger.warn(`[Local] Push failed. Attempting merge...`);

      +          // We use standard merge (no-rebase) as it handles 'meta.json'
      append conflicts slightly better 

      +          // in automated scenarios than rebase, which can get stuck.

      +          await execGit(['pull', '--no-rebase', 'origin', branch], dir,
      logger);
                 await execGit(['push', 'origin', branch], dir, logger);
             }
           }
    patchStrategy: standard-diff
snapshot:
  src/sandbox/execute.ts: >-
    import { Kernel } from '../kernel/core.js';

    import { createSandbox } from './isolate.js';

    import { createSandboxBridge } from './bridge.js';

    import { bundleDependencySync } from './bundler.js';

    import { transformSync } from 'esbuild';

    import * as path from 'path';


    export interface ExecutionResult {
      // eslint-disable-next-line @typescript-eslint/no-explicit-any
      result: any;
      logs: string[];
      error?: string;
    }


    /**
     * Resolves a module path within the VFS using standard Node.js resolution logic.
     * Checks: path, path.ts, path.js, path/index.ts, path/index.js
     */
    function resolveVfsPath(vfs: Kernel['vfs'], baseDir: string, importPath:
    string): string | null {
      const candidates: string[] = [];
      
      // Resolve absolute path based on import type
      // If it starts with '/', it's absolute (from VFS root).
      // Otherwise, it's relative to baseDir.
      const target = importPath.startsWith('/') 
        ? importPath 
        : path.join(baseDir, importPath);

      // 1. Exact match (e.g. require('./foo.ts'))
      candidates.push(target);
      
      // 2. Extensions (e.g. require('./foo'))
      candidates.push(`${target}.ts`);
      candidates.push(`${target}.js`);
      
      // 3. Directory Indices
      candidates.push(path.join(target, 'index.ts'));
      candidates.push(path.join(target, 'index.js'));

      for (const c of candidates) {
        try {
          // Synchronous check is required for the sync require shim
          vfs.readSync(c);
          return c;
        } catch {
          continue;
        }
      }
      return null;
    }


    /**
     * Executes a tool script within a secure sandbox.
     * 
     * @param kernel The TGP Kernel instance
     * @param code The TypeScript source code of the tool
     * @param args The arguments object to pass to the tool (as 'args' global)
     * @param filePath Optional path of the tool being executed (used for relative imports)
     */
    // eslint-disable-next-line @typescript-eslint/no-explicit-any

    export async function executeTool(kernel: Kernel, code: string, args:
    Record<string, any> = {}, filePath: string = 'root.ts'):
    Promise<ExecutionResult> {
      const sandbox = createSandbox({
        memoryLimitMb: 128,
        timeoutMs: 5000 // 5s hard limit
      });
      
      const logs: string[] = [];

      try {
        // 1. Setup Bridge
        // We pass the kernel directly.
        const bridge = createSandboxBridge({
          kernel,
          onLog: (msg) => logs.push(msg)
        });

        // 2. Module Orchestration (The 'require' Bridge)
        // This host function is called synchronously from the Guest.
        const __tgp_load_module = (baseDir: string, importId: string) => {
          // 1. Handle whitelisted node modules (bare specifiers)
          if (!importId.startsWith('.') && !importId.startsWith('/')) {
            if (!kernel.config.allowedImports.includes(importId)) {
              throw new Error(`Security Violation: Import of module '${importId}' is not allowed. Allowed modules are: ${kernel.config.allowedImports.join(', ')}`);
            }
            try {
              const bundledCode = bundleDependencySync(importId);
              return {
                code: bundledCode,
                path: `/__node_modules__/${importId}`, // Virtual path for caching
                dirname: `/__node_modules__`,
              };
            } catch (err: unknown) {
              const msg = err instanceof Error ? err.message : String(err);
              throw new Error(`Failed to bundle allowed module '${importId}': ${msg}`);
            }
          }

          // 2. Resolve Local Modules (VFS)
          const resolvedPath = resolveVfsPath(kernel.vfs, baseDir, importId);

          if (resolvedPath === null) {
            throw new Error(`Cannot find module '${importId}' from '${baseDir}'`);
          }

          try {
            const raw = kernel.vfs.readSync(resolvedPath);
            const transformed = transformSync(raw, {
              loader: 'ts',
              format: 'cjs',
              target: 'es2020',
            });
            
            return {
              code: transformed.code,
              path: resolvedPath,
              dirname: path.dirname(resolvedPath)
            };
          } catch (err: unknown) {
            const msg = err instanceof Error ? err.message : String(err);
            throw new Error(`Failed to load module '${importId}' from '${baseDir}': ${msg}`);
          }
        };

        // 3. Shim Injection
        // We prepend a CommonJS loader shim to the user code.
        // This allows 'require' to work by calling back to the host via __tgp_load_module.
        // It includes a cache to prevent reloading the same module within a single execution.
        const shim = `
          const __moduleCache = {};

          function __makeRequire(baseDir) {
            return function(id) {
              // HOST INTERACTION: Resolve module path and get its source code from the host.
              // This is a synchronous call to the Node.js environment.
              
              let mod;
              if (typeof __tgp_load_module.applySync === 'function') {
                 mod = __tgp_load_module.applySync(undefined, [baseDir, id]);
              } else {
                 mod = __tgp_load_module(baseDir, id);
              }

              // CACHE CHECK: If the module has already been loaded, return it from the cache.
              if (__moduleCache[mod.path]) {
                return __moduleCache[mod.path].exports;
              }

              // MODULE EXECUTION: If it's a new module, execute its code.
              const newModule = { exports: {} };

              // Before executing, store the module object in the cache to handle circular dependencies.
              __moduleCache[mod.path] = newModule;

              // We provide the module with its own 'exports' object, a 'require' function
              // scoped to its own directory, and other CommonJS globals.
              const fun = new Function('exports', 'require', 'module', '__filename', '__dirname', mod.code);

              // Execute the module's code.
              fun(newModule.exports, __makeRequire(mod.dirname), newModule, mod.path, mod.dirname);

              // The 'newModule.exports' object is now populated.
              return newModule.exports;
            };
          }

          // Setup Global Require for the entry point
          global.require = __makeRequire('${path.dirname(filePath)}');
        `;

        const context = {
          ...bridge, // { tgp: { ... } }
          args,
          __tgp_load_module // Injected as Reference
        };

        // Combine Shim + User Code
        // We wrap user code to provide top-level CommonJS variables if needed, 
        // but standard TGP tools are just scripts. 
        // We append the code. The 'shim' sets up 'global.require'.
        const fullScript = shim + '\n' + code;

        const result = await sandbox.compileAndRun(fullScript, context);
        return { result, logs };

      } catch (error) {
        const errMsg = error instanceof Error ? error.message : String(error);
        kernel.logger.error(`Tool Execution Failed:`, error);
        return { result: null, logs, error: errMsg };
      } finally {
        sandbox.dispose();
      }
    }
  src/kernel/git.ts: >2
     
    import * as git from 'isomorphic-git';

    import { TGPConfig, Logger } from '../types.js';

    import * as path from 'path';

    import { spawn } from 'child_process';


    /**
     * The Git Interface required by the Kernel.
     * We rely on the 'fs' interface compatible with isomorphic-git.
     */
    export interface GitBackend {
      hydrate(): Promise<void>;
      persist(message: string, files: string[]): Promise<void>;
    }


    export interface GitDependencies {
      // eslint-disable-next-line @typescript-eslint/no-explicit-any
      fs: any;
      // eslint-disable-next-line @typescript-eslint/no-explicit-any
      http: any;
    }


    /**
     * Strategy interface for persisting changes to the upstream repository.
     */
    interface GitWriteStrategy {
      persist(message: string, files: string[]): Promise<void>;
    }


    /**
     * Adapter interface for Git Hosting Platforms.
     * Handles platform-specific API calls like creating Pull Requests.
     */
    interface GitPlatformAdapter {
      createPullRequest(opts: {
        title: string;
        branch: string;
        base: string;
        body: string;
      }): Promise<void>;
    }


    class GitHubAdapter implements GitPlatformAdapter {
      constructor(
        private repo: string,
        private token: string,
        private apiBaseUrl: string,
        private logger: Logger
      ) {}

      async createPullRequest(opts: { title: string; branch: string; base: string; body: string }): Promise<void> {
        const [owner, repoName] = this.repo.split('/');
        const url = new URL(`/repos/${owner}/${repoName}/pulls`, this.apiBaseUrl).href;

        this.logger.info(`Creating Pull Request on ${this.repo}...`);

        try {
          const response = await fetch(url, {
            method: 'POST',
            headers: {
              'Authorization': `token ${this.token}`,
              'Accept': 'application/vnd.github.v3+json',
              'Content-Type': 'application/json',
            },
            body: JSON.stringify({
              title: opts.title,
              head: opts.branch,
              base: opts.base,
              body: opts.body,
            }),
          });

          const result = await response.json();
          if (response.ok) {
            this.logger.info(`Successfully created Pull Request: ${result.html_url}`);
          } else if (response.status === 422) {
            this.logger.warn(`Could not create PR (it may already exist): ${JSON.stringify(result.errors)}`);
          } else {
            this.logger.error(`GitHub API Error: ${response.status} ${response.statusText}`, result);
          }
        } catch (e) {
          this.logger.error('Failed to create pull request via API.', e);
          throw e;
        }
      }
    }


    class NotImplementedAdapter implements GitPlatformAdapter {
      constructor(private provider: string) {}
      async createPullRequest(): Promise<void> {
        throw new Error(`Git Provider '${this.provider}' is not yet implemented.`);
      }
    }


    // --- Local Git Implementation (Shell-based) ---

    // Used for E2E testing and Air-gapped environments

    async function execGit(args: string[], cwd: string, logger: Logger):
    Promise<void> {
      logger.debug(`[Local] Executing: git ${args.join(' ')} in ${cwd}`);
      return new Promise((resolve, reject) => {
        const proc = spawn('git', args, { cwd, stdio: 'pipe' });
        let output = '';
        proc.stdout.on('data', d => output += d.toString());
        proc.stderr.on('data', d => output += d.toString());
        
        proc.on('close', (code) => {
          if (code === 0) resolve();
          else reject(new Error(`Git command failed: git ${args.join(' ')} in ${cwd}\nOutput: ${output}`));
        });
      });
    }


    function createLocalGitBackend(config: TGPConfig, logger: Logger):
    GitBackend {
      const dir = config.rootDir;
      const { repo, branch } = config.git;

      return {
        async hydrate() {
          const fs = await import('node:fs/promises');
          const gitDirExists = await fs.stat(path.join(dir, '.git')).then(() => true).catch(() => false);
          
          if (!gitDirExists) {
            logger.info(`[Local] Cloning ${repo} into ${dir}...`);
            await fs.mkdir(path.dirname(dir), { recursive: true });
            // Clone needs to happen in parent dir
            // We assume 'repo' is an absolute path to a bare repo
            await execGit(['clone', repo, path.basename(dir)], path.dirname(dir), logger);
            
            // Ensure we are on correct branch
            try {
                await execGit(['checkout', branch], dir, logger);
            } catch {
                logger.warn(`[Local] Failed to checkout ${branch}, assuming default.`);
            }
          } else {
            logger.info(`[Local] Pulling latest from ${repo}...`);
            await execGit(['pull', 'origin', branch], dir, logger);
          }
        },

        async persist(message: string, files: string[]) {
          if (files.length === 0) return;
          logger.info(`[Local] Persisting ${files.length} files...`);
          
          for (const f of files) {
            await execGit(['add', f], dir, logger);
          }
          
          try {
            await execGit(['commit', '-m', message], dir, logger);
          } catch(e) {
             // Commit might fail if no changes
             logger.warn(`[Local] Commit failed (empty?):`, String(e));
             return;
          }

          try {
              await execGit(['push', 'origin', branch], dir, logger);
          } catch (_e) {
              // Handle non-fast-forward by pulling first (simple auto-merge)
              logger.warn(`[Local] Push failed. Attempting rebase...`);
              await execGit(['pull', '--rebase', 'origin', branch], dir, logger);
              await execGit(['push', 'origin', branch], dir, logger);
          }
        }
      };
    }


    /**
     * Factory to create the Git Backend based on configuration.
     */
    export function createGitBackend(deps: GitDependencies, config: TGPConfig,
    logger: Logger): GitBackend {
      const dir = config.rootDir;
      const { repo, auth, branch, writeStrategy, apiBaseUrl, provider } = config.git;
      const { fs, http } = deps;

      if (provider === 'local') {
        return createLocalGitBackend(config, logger);
      }

      // Configuration for isomorphic-git
      const gitOpts = {
        fs,
        dir,
        http,
        onAuth: () => ({ username: auth.token }),
      };

      const author = {
        name: auth.user,
        email: auth.email,
      };

      // Select Platform Adapter
      let platformAdapter: GitPlatformAdapter;
      if (provider === 'github') {
        platformAdapter = new GitHubAdapter(repo, auth.token, apiBaseUrl, logger);
      } else {
        platformAdapter = new NotImplementedAdapter(provider);
      }

      // --- Strategy Implementations ---

      const directStrategy: GitWriteStrategy = {
        async persist(message: string, filesToAdd: string[]) {
          if (filesToAdd.length === 0) return;

          // 1. Add files
          for (const filepath of filesToAdd) {
            try {
               // check if file exists before adding
               await git.add({ ...gitOpts, filepath });
            } catch (e) {
               logger.warn(`Git Add failed for ${filepath}`, e);
               throw new Error(`Failed to stage file ${filepath}: ${e instanceof Error ? e.message : String(e)}`);
            }
          }

          try {
            // 2. Commit
            const sha = await git.commit({
              ...gitOpts,
              message,
              author,
            });
            logger.info(`Committed ${sha.slice(0, 7)}: ${message}`);

            // 3. Push
            logger.info(`Pushing to ${branch}...`);
            await git.push({
              ...gitOpts,
              remote: 'origin',
              ref: branch,
            });
          } catch (e) {
            logger.error(`Git Commit/Push failed:`, e);
            throw new Error(`Failed to persist changes to Git: ${e instanceof Error ? e.message : String(e)}`);
          }
        }
      };

      const prStrategy: GitWriteStrategy = {
        async persist(message: string, files: string[]) {
          if (files.length === 0) return;
          
          // 1. Get current branch
          const currentBranch = await git.currentBranch({ ...gitOpts }) ?? 'HEAD';
          
          // 2. If we are on the protected branch (main/master), we must fork
          let targetBranch = currentBranch;
          
          if (currentBranch === branch) {
             const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
             // Sanitize message for branch name
             const safeMsg = message.replace(/[^a-zA-Z0-9-]/g, '-').slice(0, 30);
             targetBranch = `tgp/feat-${timestamp}-${safeMsg}`;
             
             logger.info(`Switching to new branch: ${targetBranch}`);
             
             await git.branch({ ...gitOpts, ref: targetBranch });
             await git.checkout({ ...gitOpts, ref: targetBranch });
          } else {
             logger.info(`Already on feature branch: ${targetBranch}`);
          }

          for (const filepath of files) {
            await git.add({ ...gitOpts, filepath }).catch(e => logger.warn(`Git Add failed ${filepath}`, e));
          }

          await git.commit({
            ...gitOpts,
            message: message,
            author,
          });
          
          logger.info(`Changes committed to ${targetBranch}.`);
          
          // Try to push the feature branch if auth is present
          try {
              await git.push({
                ...gitOpts,
                remote: 'origin',
                ref: targetBranch,
              });
              logger.info(`Pushed ${targetBranch} to origin.`);
              await platformAdapter.createPullRequest({
                title: message,
                branch: targetBranch,
                base: branch,
                body: `Forged by TGP.\nCommit Message: ${message}`,
              });
          } catch (e) {
              logger.warn(`Failed to push feature branch. Changes are local only.`, e);
          }
        }
      };

      // Select Strategy
      const strategy = writeStrategy === 'pr' ? prStrategy : directStrategy;

      return {
        async hydrate() {
          try {
            // 1. Check if repo exists locally
            const gitDirExists = (await fs.promises.stat(path.join(dir, '.git'))
              .then(() => true)
              .catch(() => false)) as boolean;

            if (!gitDirExists) {
              // Clone
              logger.info(`Cloning ${repo} into ${dir}...`);
              await git.clone({
                ...gitOpts,
                url: `https://github.com/${repo}.git`,
                ref: branch,
                singleBranch: true,
                depth: 1,
              });
            } else {
              // Pull
              logger.info(`Pulling latest from ${repo}...`);
              await git.pull({
                ...gitOpts,
                remote: 'origin',
                ref: branch,
                singleBranch: true,
                author,
              });
            }
          } catch (error) {
            logger.error(`Git Hydration Failed:`, error);
            // Fail fast: The agent cannot operate without a consistent filesystem state.
            throw error;
          }
        },

        async persist(message: string, filesToAdd: string[]) {
          return strategy.persist(message, filesToAdd);
        }
      };
    }
approved: true
linesAdded: 35
linesRemoved: 11
linesDifference: 46
gitCommittedAt: null
status: committed
id: 50
